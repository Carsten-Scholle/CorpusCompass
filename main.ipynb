{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import csv\n", "import json\n", "import re\n", "from copy import copy\n", "from colors import color_print, info, warning, error"]}, {"cell_type": "markdown", "metadata": {}, "source": ["REGEX used to find the tags"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["square_regex = re.compile(r\"(\\[\\$[\\S ]*?\\])\")\n", "feat_regex = re.compile(r'\\[\\$([\\S ]*?)\\]')\n", "sequence_regex = re.compile(r\"({[\\S ]+})\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["variables paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dependent_variable_path = './dependent_variables.json'\n", "independent_variable_path = './independent_variables.json'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["path for the transcription file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transcription_path = \"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["separator for the csv file<br>\n", "Alternatives are:<br>\n", "semicolon: ';'<br>\n", "comma: ','"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["separator = '\\t'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def remove_features(corpus):\n", "    \"\"\"\n", "    Remove the features from the corpus\n", "    \"\"\"\n", "    corpus = copy(corpus)\n", "    words = square_regex.findall(corpus)\n", "    for w in words:\n", "        try:\n", "            text = w.rsplit(\".\", 1)[1][:-1]\n", "            corpus = corpus.replace(w, text)\n", "        except IndexError:\n", "            color_print(f\"I found an error for the tag '{w}'. Myabe it does not have a point in it?\\n\"\n", "                        f\"Please check the tag and try again.\", \"error\")\n", "            exit()\n", "            continue\n", "    return corpus"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_name(line):\n", "    return line.split(\" \")[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(transcription_path):\n", "    # Load the dependent variable\n", "    with open(dependent_variable_path, 'r') as f:\n", "        dependent_variable = json.load(f)\n\n", "    # Load the dependent variable\n", "    with open(independent_variable_path, 'r') as f:\n", "        independent_variable = json.load(f)\n", "    dependent_variable.update(independent_variable)\n", "    # get an inverse of the dependent variable\n", "    idv = {}\n", "    for k, v in dependent_variable.items():\n", "        if isinstance(v, list):\n", "            for i in v:\n", "                idv[i] = k\n", "        else:\n", "            idv[v] = k\n\n", "    # ask user for path input\n", "    path = input(info(f'Drag and drop the transcription file (.txt), or leave blank if \"{transcription_path}\" '\n", "                      f'is correct: '))\n", "    print(\"\\n\")\n", "    if len(path) > 0:\n", "        transcription_path = path.strip()\n", "    output_path = transcription_path.replace('.txt', '_output.csv')\n\n", "    # opend the file\n", "    with open(transcription_path, 'r+', encoding=\"utf16\") as f:\n", "        trans = f.readlines()\n", "    trans = trans[2:]\n", "    trans = [x.strip() for x in trans]\n", "    trans = [x for x in trans if x != '']\n\n", "    # ask for interviwers name\n", "    interviewers = input(info(f'Add the name(s) of the interviewer(s) (separated by comma), '\n", "                              f'leave empty for classical interviewer-interviewees structure: '))\n", "    print(\"\\n\")\n", "    if len(interviewers) > 0:\n", "        interviewers = interviewers.split(',')\n", "    else:\n", "        interviewers = trans[0][0]\n\n", "    # ask for previous line\n", "    previous_line = input(info(f'When generating the final cvs file, I can also include the speaker utterance.'\n", "                               f' Do you want me to include it? (y/n): '))\n", "    print(\"\\n\")\n", "    if previous_line == 'y':\n", "        previous_line = True\n", "    else:\n", "        previous_line = False\n\n", "    # get speak/list names\n", "    names = [get_name(x).strip() for x in trans]\n", "    names = set(names)\n\n", "    # remove all mention of interviwers in names\n", "    for i in interviewers:\n", "        names = [x for x in names if i not in x]\n", "    interviewees = list(names)\n\n", "    # notify user about names\n", "    print(warning(f\"I found the following names: {', '.join(interviewees)}\"))\n\n", "    # compile regex to find features\n", "    csv_header = list(dependent_variable.keys())\n\n", "    # define the end of the csv\n", "    csv_end = ['sequence in sentence', 'unk']\n", "    if previous_line:\n", "        csv_end.insert(0, 'previous line')\n", "    csv_header = [\"text\"] + csv_header + csv_end\n", "    csv_file = [csv_header]\n", "    unk_categories = []\n\n", "    # for every paragraph in the transcript\n", "    for idx in range(len(trans)):\n", "        c = trans[idx]\n\n", "        # get the paragraph without features\n", "        if get_name(c) in interviewees:\n", "            sp = trans[idx - 1]\n", "        else:\n", "            continue\n", "        clean_p = remove_features(c)\n\n", "        # capture all the sequences\n", "        sequences = sequence_regex.finditer(clean_p)\n", "        sequences = [(x.start(), x.end(), x.group()) for x in sequences]\n\n", "        # get the features\n", "        tags = feat_regex.finditer(c)\n\n", "        # for every tags with features in the paragraph\n", "        for t in tags:\n", "            # get index of result + tag\n", "            index = t.start()\n", "            t = t.group(1)\n\n", "            # initialize empty row\n", "            csv_line = [\"\" for _ in range(len(csv_header))]\n\n", "            # get the features\n", "            feats = t.rsplit(\".\", 1)\n", "            text = feats[1]\n", "            feats = feats[0]\n\n", "            # for every feature in the word\n", "            for f in feats.split(\".\"):\n", "                # if the category is not present in the dict, then add to unk\n", "                if f not in idv.keys():\n", "                    unk_categories.append(f)\n", "                    csv_line[-1] = csv_line[-1] + f + \",\"\n", "                else:\n", "                    category = idv[f]\n", "                    cat_idx = csv_header.index(category)\n", "                    csv_line[cat_idx] = f\n\n", "            # add initial infos and final unk to the line\n", "            csv_line[0] = text\n", "            if previous_line:\n", "                csv_line[-3] = sp\n\n", "            # add the sequence to the line\n", "            if len(sequences) != 0:\n", "                for s in sequences:\n", "                    seq_start, seq_end, seq = sequences[0]\n", "                    if seq_start < index < seq_end:\n", "                        seq = seq.replace(\"{\", \"\").replace(\"}\", \"\")\n", "                        csv_line[-2] = seq\n", "            csv_line[-1] = csv_line[-1].strip(\",\")\n", "            csv_file.append(csv_line)\n\n", "    # write the csv\n", "    with open(output_path, \"w\", newline=\"\", encoding=\"utf16\") as f:\n", "        writer = csv.writer(f, delimiter=separator)\n", "        writer.writerows(csv_file)\n", "    color_print(f\"Done!\\nFile has been saved in '{output_path}'\",\"ok\")\n", "    if len(unk_categories) > 0:\n", "        unk_categories = set(unk_categories)\n", "        unk_categories = sorted(unk_categories)\n", "        print(warning(\n", "            f\"I have found several categories not listed in '{independent_variable_path}' or in '{dependent_variable_path}'.\\n\"\n", "            f\"Following in alphabetical order:\"))\n", "        for c in unk_categories:\n", "            print(warning(c.strip()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    try:\n", "        main(transcription_path)\n", "    except Exception as e:\n", "        print(error(f\"An error occured: {e}\"))\n", "        exit(1)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}